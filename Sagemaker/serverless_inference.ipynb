{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install torch boto3 sagemaker --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.72.1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-10 15:15:36--  https://sagemaker-us-east-1-809378912851.s3.amazonaws.com/huggingface/model.tar.gz\n",
      "Resolving sagemaker-us-east-1-809378912851.s3.amazonaws.com (sagemaker-us-east-1-809378912851.s3.amazonaws.com)... 52.216.153.116\n",
      "Connecting to sagemaker-us-east-1-809378912851.s3.amazonaws.com (sagemaker-us-east-1-809378912851.s3.amazonaws.com)|52.216.153.116|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 955270513 (911M) [binary/octet-stream]\n",
      "Saving to: ‘model.tar.gz’\n",
      "\n",
      "model.tar.gz        100%[===================>] 911.02M  37.6MB/s    in 27s     \n",
      "\n",
      "2022-01-10 15:16:03 (33.6 MB/s) - ‘model.tar.gz’ saved [955270513/955270513]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://sagemaker-us-east-1-809378912851.s3.amazonaws.com/huggingface/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-809378912851/huggingface/model.tar.gz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_archive = 'model.tar.gz'\n",
    "prefix = 'huggingface'\n",
    "model_data_url = sess.upload_data(str(model_archive), key_prefix=prefix)\n",
    "model_data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_version='4.12.3'\n",
    "pytorch_version='1.9.1'\n",
    "py_version='py38'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use boto3 to deploy with serverless inference\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm = boto3.client(service_name='sagemaker')\n",
    "sm_rt = boto3.client(service_name='sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "def name_with_timestamp(name):\n",
    "    return '{}-{}'.format(name, strftime('%Y-%m-%d-%H-%M-%S', gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model_name    = name_with_timestamp('huggingface-serverless')\n",
    "huggingface_epc_name      = name_with_timestamp('huggingface-serverless-epc')\n",
    "huggingface_endpoint_name = name_with_timestamp('huggingface-serverless-ep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.9.1-transformers4.12.3-cpu-py38-ubuntu20.04'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='huggingface',\n",
    "    base_framework_version=f'pytorch{pytorch_version}',\n",
    "    region=region,\n",
    "    version=transformers_version,\n",
    "    py_version=py_version,\n",
    "    instance_type='ml.m5.large',   # No GPU support on serverless inference\n",
    "    image_scope='inference'\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-east-1:809378912851:model/huggingface-serverless-2022-01-10-15-16-16'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model_response = sm.create_model(\n",
    "    ModelName=huggingface_model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            'Image': image_uri,\n",
    "            'Mode': 'SingleModel',\n",
    "            'ModelDataUrl': model_data_url\n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "\n",
    "create_model_response[\"ModelArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-east-1:809378912851:endpoint-config/huggingface-serverless-epc-2022-01-10-15-16-16'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=huggingface_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'single-variant',\n",
    "            'ModelName': huggingface_model_name,\n",
    "            'ServerlessConfig': {\n",
    "                'MemorySizeInMB': 6144,\n",
    "                'MaxConcurrency': 8,\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "endpoint_config_response['EndpointConfigArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-east-1:809378912851:endpoint/huggingface-serverless-ep-2022-01-10-15-16-16'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=huggingface_endpoint_name,\n",
    "    EndpointConfigName=huggingface_epc_name,\n",
    ")\n",
    "\n",
    "create_endpoint_response['EndpointArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=huggingface_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, threading, time, json\n",
    "\n",
    "sm_rt = boto3.client(service_name='sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_16 = {'inputs': \"The Phantom Menace was a waste of my life. Die, Jar Jar, die!\"}\n",
    "\n",
    "test_data_250 = {'inputs': \"Naked but not afraid, a young man roams the forest, growling in all fours. \\\n",
    "He behaves like a beast. To him, this is not a theatrical exercise but the true manifestation of his instincts. \\\n",
    "In Nathalie Biancheri's offbeat drama “Wolf,” he is one in a group of teenagers convinced their fragile human \\\n",
    "bodies don’t correspond with their animal identities. Their condition, described as “species dysphoria,” \\\n",
    "ostracizes them from society.For Jacob (George MacKay), the wolf in question, being admitted into a facility \\\n",
    "where those afflicted receive corrective treatment is a last frontier between fulfilling his parents’ wish for \\\n",
    "normalcy or running wild without remorse.Jacob steps into a pack of fellow patients and meets among several \\\n",
    "others, Rufus (Fionn O'Shea), who thinks of himself as a lovable German Shepherd, and love interest Wildcat \\\n",
    "(Lily-Rose Depp), a long house-trained resident under the thumb of a key staff member. Some of them have a \\\n",
    "hard time adjusting, and get “prop privileges” to wear costumes that bring them closer to their desired form. \\\n",
    "Despite what it entails, the setup is never played for laughs, but the opposite. Their desperation has a deep \\\n",
    "sadness. But for as much writer/director Biancheri pumps copious ideas into this concept, the solemn tone and \\\n",
    "lack of thematic focus renders the overwrought outing underwhelming. A premise like this would have been more \\\n",
    "effective had it been executed with the acidity of someone like director Yorgos Lanthimos, in which the premise \\\n",
    "could unfold as satirical commentary rather than straightforward indignation. \"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.917281150817871\n",
      "b'[{\"label\":\"LABEL_0\",\"score\":0.9800038933753967}]'\n"
     ]
    }
   ],
   "source": [
    "tick = time.time()\n",
    "response = sm_rt.invoke_endpoint(\n",
    "            EndpointName=huggingface_endpoint_name,\n",
    "            Body=json.dumps(test_data_16),\n",
    "            ContentType='application/json'\n",
    ")\n",
    "tock = time.time()\n",
    "print(tock-tick)\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd80ec44d-c5e8-4e9e-9d10-9e1a888344c6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd80ec44d-c5e8-4e9e-9d10-9e1a888344c6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Mon, 10 Jan 2022 15:21:33 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_endpoint(EndpointName=huggingface_endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=huggingface_epc_name)\n",
    "sm.delete_model(ModelName=huggingface_model_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
